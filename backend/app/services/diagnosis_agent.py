"""
AIè¯Šå®¤æ™ºèƒ½ä½“æœåŠ¡ - åŸºäºLangGraphå®ç°åŒ»ç–—é—®è¯Šæµç¨‹
"""
import json
import httpx
from typing import TypedDict, List, Optional, Literal, Callable, Awaitable, AsyncIterator
from datetime import datetime
from ..config import get_settings

settings = get_settings()


class QuickOption(TypedDict):
    """å¿«æ·é€‰é¡¹"""
    text: str
    value: str
    category: str


class DiagnosisState(TypedDict):
    """é—®è¯ŠçŠ¶æ€"""
    consultation_id: str
    user_id: int
    
    # å¯¹è¯å†å²
    messages: List[dict]
    
    # æ”¶é›†çš„ç—‡çŠ¶ä¿¡æ¯
    chief_complaint: str
    symptoms: List[str]
    symptom_details: dict
    
    # é—®è¯Šè¿›åº¦
    stage: Literal["greeting", "collecting", "deep_inquiry", "diagnosis", "completed"]
    progress: int
    questions_asked: int
    
    # AIç”Ÿæˆå†…å®¹
    current_question: str
    quick_options: List[QuickOption]
    reasoning: str
    
    # è¯Šæ–­ç»“æœ
    possible_diseases: List[dict]
    risk_level: Literal["low", "medium", "high", "emergency"]
    recommendations: dict
    
    # æ§åˆ¶æ ‡å¿—
    can_conclude: bool
    force_conclude: bool
    
    # AIè¯„ä¼°å­—æ®µï¼ˆæ–°å¢ï¼‰
    should_diagnose: bool
    confidence: int
    missing_info: List[str]


class DiagnosisAgent:
    """AIè¯Šå®¤æ™ºèƒ½ä½“"""
    
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIåŒ»ç”ŸåŠ©æ‰‹ï¼Œæ­£åœ¨è¿›è¡Œæ™ºèƒ½é—®è¯Šã€‚ä½ çš„ä»»åŠ¡æ˜¯é€šè¿‡å¯¹è¯æ”¶é›†æ‚£è€…çš„ç—‡çŠ¶ä¿¡æ¯ï¼Œå¹¶ç»™å‡ºåˆæ­¥è¯Šæ–­å»ºè®®ã€‚

é—®è¯ŠåŸåˆ™ï¼š
1. ä¸€æ¬¡åªé—®ä¸€ä¸ªé—®é¢˜ï¼Œé—®é¢˜è¦ç®€æ´æ˜äº†
2. ä»ä¸»è¯‰å¼€å§‹ï¼Œé€æ­¥æ·±å…¥äº†è§£ç—‡çŠ¶ç»†èŠ‚
3. å…³æ³¨ç—‡çŠ¶çš„æŒç»­æ—¶é—´ã€ä¸¥é‡ç¨‹åº¦ã€ä¼´éšç—‡çŠ¶
4. æ³¨æ„è¯†åˆ«å±é™©ä¿¡å·ï¼ˆçº¢æ——ç—‡çŠ¶ï¼‰
5. æ€åº¦ä¸“ä¸šã€æ¸©å’Œã€è€å¿ƒ

æ³¨æ„ï¼šä½ çš„å›ç­”ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç”Ÿçš„è¯Šæ–­ã€‚"""

    QUESTION_PROMPT = """åŸºäºä»¥ä¸‹å¯¹è¯å†å²ï¼Œç”Ÿæˆä¸‹ä¸€ä¸ªé—®è¯Šé—®é¢˜ã€‚

å½“å‰æ”¶é›†çš„ä¿¡æ¯ï¼š
- ä¸»è¯‰ï¼š{chief_complaint}
- å·²æ”¶é›†ç—‡çŠ¶ï¼š{symptoms}
- ç—‡çŠ¶è¯¦æƒ…ï¼š{symptom_details}
- å·²æé—®æ¬¡æ•°ï¼š{questions_asked}

å¯¹è¯å†å²ï¼š
{messages}

è¦æ±‚ï¼š
1. æ ¹æ®å·²æœ‰ä¿¡æ¯ï¼Œæå‡ºä¸‹ä¸€ä¸ªæœ€ç›¸å…³çš„é—®é¢˜
2. é—®é¢˜è¦å…·ä½“ã€æœ‰é’ˆå¯¹æ€§
3. å¦‚æœä¿¡æ¯è¶³å¤Ÿï¼Œå¯ä»¥å¼€å§‹æ€»ç»“

è¯·ç›´æ¥è¾“å‡ºé—®é¢˜ï¼Œä¸è¦æœ‰å¤šä½™çš„å‰ç¼€ã€‚"""

    QUICK_OPTIONS_PROMPT = """ä½ åˆšåˆšå‘æ‚£è€…æå‡ºäº†ä»¥ä¸‹é—®é¢˜ï¼š
"{question}"

åŸºäºè¿™ä¸ªé—®é¢˜ï¼Œé¢„æµ‹æ‚£è€…æœ€å¯èƒ½çš„3-5ä¸ªå›ç­”é€‰é¡¹ã€‚

è¦æ±‚ï¼š
1. é€‰é¡¹è¦è¦†ç›–å¸¸è§æƒ…å†µï¼ˆè‚¯å®š/å¦å®š/å…·ä½“æè¿°ï¼‰
2. é€‰é¡¹è¦ç®€æ´æ˜äº†ï¼Œä¾¿äºç‚¹å‡»
3. å¿…é¡»åŒ…å«"æ²¡æœ‰"æˆ–"éƒ½ä¸ç¬¦åˆ"è¿™ç±»å¦å®šé€‰é¡¹
4. å¦‚æœæ˜¯ç—‡çŠ¶æè¿°ç±»é—®é¢˜ï¼Œæä¾›å…·ä½“çš„ç—‡çŠ¶é€‰é¡¹
5. **é‡è¦ï¼štext å’Œ value éƒ½å¿…é¡»ä½¿ç”¨ä¸­æ–‡ï¼Œä¸è¦ä½¿ç”¨è‹±æ–‡æˆ–æ‹¼éŸ³**

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼š
{{"options": [{{"text": "é€‰é¡¹æ–‡æœ¬", "value": "é€‰é¡¹å€¼", "category": "ç—‡çŠ¶ç±»åˆ«"}}]}}

ç¤ºä¾‹ï¼š{{"options": [{{"text": "æŒç»­2-3å¤©", "value": "æŒç»­2-3å¤©", "category": "æ—¶é—´"}}]}}"""

    ASSESSMENT_PROMPT = """è¯„ä¼°å½“å‰æ”¶é›†çš„ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿåšå‡ºåˆæ­¥è¯Šæ–­ã€‚

å·²æ”¶é›†ä¿¡æ¯ï¼š
- ä¸»è¯‰ï¼š{chief_complaint}
- ç—‡çŠ¶åˆ—è¡¨ï¼š{symptoms}
- ç—‡çŠ¶è¯¦æƒ…ï¼š{symptom_details}
- å·²æé—®æ¬¡æ•°ï¼š{questions_asked}

å¯¹è¯å†å²ï¼š
{messages}

è¯„ä¼°æ ‡å‡†ï¼š
1. æ˜¯å¦æ”¶é›†äº†ä¸»è¦ç—‡çŠ¶çš„æŒç»­æ—¶é—´ã€ä¸¥é‡ç¨‹åº¦
2. æ˜¯å¦æ’é™¤äº†å±é™©ä¿¡å·ï¼ˆçº¢æ——ç—‡çŠ¶ï¼‰
3. æ˜¯å¦äº†è§£äº†ä¼´éšç—‡çŠ¶
4. ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿåšå‡ºåˆæ­¥åˆ¤æ–­

è¯·ç»¼åˆåˆ¤æ–­é—®è¯Šè¿›åº¦å’Œæ˜¯å¦åº”è¯¥ç»“æŸé—®è¯Šè¿›å…¥è¯Šæ–­é˜¶æ®µã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{{
    "progress": 0åˆ°100çš„æ•°å­—ï¼ˆè¡¨ç¤ºé—®è¯Šå®Œæˆåº¦ï¼Œç™¾åˆ†æ¯”ï¼‰,
    "should_diagnose": trueæˆ–falseï¼ˆæ˜¯å¦åº”ç«‹å³è¿›å…¥è¯Šæ–­é˜¶æ®µï¼‰,
    "can_conclude": trueæˆ–falseï¼ˆå½“å‰ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿå‡ºè¯Šæ–­ï¼‰,
    "confidence": 0åˆ°100çš„æ•°å­—ï¼ˆè¯Šæ–­ç½®ä¿¡åº¦ï¼‰,
    "missing_info": ["ç¼ºå¤±çš„å…³é”®ä¿¡æ¯1", "ç¼ºå¤±çš„å…³é”®ä¿¡æ¯2"],
    "reasoning": "è¯„ä¼°ç†ç”±"
}}"""

    INITIAL_OPTIONS_PROMPT = """æ ¹æ®æ‚£è€…çš„ä¸»è¯‰æˆ–å¸¸è§å°±è¯Šåœºæ™¯ï¼Œç”Ÿæˆ4-5ä¸ªåˆå§‹å¿«æ·é€‰é¡¹ä¾›æ‚£è€…é€‰æ‹©ã€‚

å½“å‰ä¸»è¯‰ï¼š{chief_complaint}

è¦æ±‚ï¼š
1. é€‰é¡¹åº”è¦†ç›–å¸¸è§çš„ç—‡çŠ¶ç±»åˆ«
2. é€‰é¡¹è¦ç®€æ´æ˜äº†ï¼Œä¾¿äºç‚¹å‡»
3. å¿…é¡»åŒ…å«ä¸€ä¸ª"å…¶ä»–ç—‡çŠ¶"æˆ–"ä¸ç¡®å®š"ç±»çš„é€‰é¡¹
4. å¦‚æœæœ‰ä¸»è¯‰ï¼Œé€‰é¡¹åº”ä¸ä¸»è¯‰ç›¸å…³ï¼›å¦‚æœæ²¡æœ‰ä¸»è¯‰ï¼Œæä¾›å¸¸è§ç—‡çŠ¶ç±»åˆ«
5. **é‡è¦ï¼štext å’Œ value éƒ½å¿…é¡»ä½¿ç”¨ä¸­æ–‡ï¼Œä¸è¦ä½¿ç”¨è‹±æ–‡æˆ–æ‹¼éŸ³**

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼š
{{"options": [{{"text": "é€‰é¡¹æ–‡æœ¬", "value": "é€‰é¡¹å€¼", "category": "ç—‡çŠ¶ç±»åˆ«"}}]}}

ç¤ºä¾‹ï¼š{{"options": [{{"text": "å’³å—½å‘çƒ§", "value": "å’³å—½å‘çƒ§", "category": "å‘¼å¸ç³»ç»Ÿ"}}]}}"""

    DIAGNOSIS_PROMPT = """åŸºäºä»¥ä¸‹æ‚£è€…ä¿¡æ¯ï¼Œç”Ÿæˆå®Œæ•´çš„è¯Šæ–­æŠ¥å‘Šã€‚

ä¸»è¯‰ï¼š{chief_complaint}
ç—‡çŠ¶è¯¦æƒ…ï¼š{symptom_details}
å¯¹è¯å†å²ï¼š{messages}

ç”Ÿæˆå†…å®¹åŒ…æ‹¬ï¼š
1. ç—‡çŠ¶æ€»ç»“
2. å¯èƒ½çš„ç–¾ç—…ï¼ˆæŒ‰å¯èƒ½æ€§æ’åºï¼Œæœ€å¤š3ä¸ªï¼‰
3. é£é™©ç­‰çº§è¯„ä¼°ï¼ˆlow/medium/high/emergencyï¼‰
4. å°±è¯Šå»ºè®®ï¼ˆç§‘å®¤ã€ç´§æ€¥ç¨‹åº¦ï¼‰
5. ç”Ÿæ´»å»ºè®®

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{{
    "summary": "ç—‡çŠ¶æ€»ç»“",
    "diseases": [
        {{"name": "ç–¾ç—…åç§°", "probability": "å¯èƒ½æ€§æè¿°", "description": "ç®€è¦è¯´æ˜"}}
    ],
    "risk_level": "low/medium/high/emergency",
    "risk_warning": "é£é™©æç¤ºï¼ˆå¦‚æœæ˜¯highæˆ–emergencyï¼‰",
    "recommendations": {{
        "department": "å»ºè®®å°±è¯Šç§‘å®¤",
        "urgency": "å°±è¯Šç´§æ€¥ç¨‹åº¦",
        "lifestyle": ["ç”Ÿæ´»å»ºè®®1", "ç”Ÿæ´»å»ºè®®2"]
    }}
}}"""

    def __init__(self):
        self.api_url = f"{settings.LLM_BASE_URL}/chat/completions"
        self.api_key = settings.LLM_API_KEY
        self.model = settings.LLM_MODEL

    async def _call_llm(self, system_prompt: str, user_prompt: str, temperature: float = 0.7) -> str:
        """è°ƒç”¨LLMï¼ˆéæµå¼ï¼‰"""
        if not self.api_key:
            return ""
        
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    self.api_url,
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.model,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        "temperature": temperature,
                        "max_tokens": 1000
                    }
                )
                
                if response.status_code == 200:
                    data = response.json()
                    choices = data.get("choices", [])
                    if choices:
                        return choices[0].get("message", {}).get("content", "")
        except Exception as e:
            print(f"LLMè°ƒç”¨å¼‚å¸¸: {e}")
        
        return ""

    async def _stream_llm(
        self,
        system_prompt: str,
        user_prompt: str,
        temperature: float = 0.7,
        on_chunk: Optional[Callable[[str], Awaitable[None]]] = None
    ) -> str:
        """
        æµå¼è°ƒç”¨LLMï¼Œæ¯æ”¶åˆ°ä¸€ä¸ªtoken chunkå°±è°ƒç”¨on_chunkå›è°ƒ
        è¿”å›å®Œæ•´çš„ç´¯ç§¯æ–‡æœ¬
        """
        if not self.api_key:
            return ""
        
        full_content = ""
        
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                async with client.stream(
                    "POST",
                    self.api_url,
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.model,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        "temperature": temperature,
                        "max_tokens": 1000,
                        "stream": True
                    }
                ) as response:
                    if response.status_code != 200:
                        print(f"LLMæµå¼è°ƒç”¨å¤±è´¥: {response.status_code}")
                        return ""
                    
                    async for line in response.aiter_lines():
                        if not line:
                            continue
                        if line.startswith("data: "):
                            data_str = line[6:]
                            if data_str.strip() == "[DONE]":
                                break
                            try:
                                data = json.loads(data_str)
                                choices = data.get("choices", [])
                                if choices:
                                    delta = choices[0].get("delta", {})
                                    content = delta.get("content", "")
                                    if content:
                                        full_content += content
                                        if on_chunk:
                                            await on_chunk(content)
                            except json.JSONDecodeError:
                                continue
        except Exception as e:
            print(f"LLMæµå¼è°ƒç”¨å¼‚å¸¸: {e}")
        
        return full_content

    def _format_messages(self, messages: List[dict]) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²"""
        formatted = []
        for msg in messages[-10:]:  # åªå–æœ€è¿‘10æ¡
            role = "æ‚£è€…" if msg.get("role") == "user" else "åŒ»ç”Ÿ"
            formatted.append(f"{role}: {msg.get('content', '')}")
        return "\n".join(formatted)

    async def generate_initial_options(self, chief_complaint: str = "") -> List[QuickOption]:
        """ç”Ÿæˆé¦–è½®å¿«æ·é€‰é¡¹ - ç”± AI ç”Ÿæˆ"""
        prompt = self.INITIAL_OPTIONS_PROMPT.format(
            chief_complaint=chief_complaint or "æ— ï¼ˆç”¨æˆ·åˆšå¼€å§‹é—®è¯Šï¼‰"
        )
        
        response = await self._call_llm(self.SYSTEM_PROMPT, prompt, temperature=0.5)
        
        default_options = [
            {"text": "å¤´ç—›å¤´æ™•", "value": "å¤´ç—›å¤´æ™•", "category": "ç¥ç»ç³»ç»Ÿ"},
            {"text": "å’³å—½å‘çƒ§", "value": "å’³å—½å‘çƒ§", "category": "å‘¼å¸ç³»ç»Ÿ"},
            {"text": "èƒƒç—›è…¹æ³»", "value": "èƒƒç—›è…¹æ³»", "category": "æ¶ˆåŒ–ç³»ç»Ÿ"},
            {"text": "çš®è‚¤é—®é¢˜", "value": "çš®è‚¤é—®é¢˜", "category": "çš®è‚¤ç§‘"},
            {"text": "å…¶ä»–ç—‡çŠ¶", "value": "å…¶ä»–ç—‡çŠ¶", "category": "å…¶ä»–"}
        ]
        
        try:
            # å¤„ç†å¯èƒ½çš„markdownä»£ç å—
            if "```json" in response:
                response = response.split("```json")[1].split("```")[0]
            elif "```" in response:
                response = response.split("```")[1].split("```")[0]
            
            data = json.loads(response.strip())
            raw_options = data.get("options", [])
            
            # ç¡®ä¿æœ‰"å…¶ä»–/ä¸ç¡®å®š"ç±»é€‰é¡¹
            has_other = any(
                "å…¶ä»–" in opt.get("text", "") or "ä¸ç¡®å®š" in opt.get("text", "") 
                for opt in raw_options
            )
            if not has_other:
                raw_options.append({"text": "å…¶ä»–ç—‡çŠ¶", "value": "å…¶ä»–ç—‡çŠ¶", "category": "å…¶ä»–"})
            
            # å¼ºåˆ¶å°† value è®¾ä¸ºä¸­æ–‡ textï¼Œé˜²æ­¢ LLM è¿”å›è‹±æ–‡ value
            formatted_options = []
            for opt in raw_options:
                text = opt.get("text") or opt.get("value") or ""
                if not text:
                    continue
                formatted_options.append({
                    "text": text,
                    "value": text,  # å¼ºåˆ¶ä½¿ç”¨ä¸­æ–‡ text ä½œä¸º value
                    "category": opt.get("category") or "å…¶ä»–"
                })
            
            return formatted_options[:5]  # æœ€å¤š5ä¸ªé€‰é¡¹
        except (json.JSONDecodeError, KeyError):
            # è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é€‰é¡¹
            return default_options

    async def greet(self, state: DiagnosisState) -> DiagnosisState:
        """é—®å€™æ‚£è€…ï¼Œå¼€å§‹é—®è¯Š"""
        greeting = "ä½ å¥½~æˆ‘æ˜¯ä½ çš„AIåŒ»ç”Ÿï¼Œæˆ‘å°†é€šè¿‡æ·±åº¦é—®è¯Šäº†è§£ä½ çš„å¥åº·çŠ¶å†µï¼Œå¹¶æä¾›æ˜ç¡®çš„è¯Šç–—å»ºè®®ã€‚\n\nå¥½çš„ï¼Œç°åœ¨è¯·æè¿°ç—…æƒ…ï¼Œä½ è¾“å…¥çš„ä¿¡æ¯è¶Šè¯¦ç»†ï¼Œæˆ‘çš„å›ç­”è¶Šç²¾å‡†å“¦~"
        
        state["current_question"] = greeting
        state["stage"] = "collecting"
        state["messages"].append({
            "role": "assistant",
            "content": greeting,
            "timestamp": datetime.now().isoformat()
        })
        
        # ç”± AI ç”Ÿæˆé¦–è½®å¿«æ·é€‰é¡¹
        state["quick_options"] = await self.generate_initial_options(state.get("chief_complaint", ""))
        
        return state

    async def analyze_input(self, state: DiagnosisState, user_input: str) -> DiagnosisState:
        """åˆ†ææ‚£è€…è¾“å…¥"""
        # è®°å½•ç”¨æˆ·æ¶ˆæ¯
        state["messages"].append({
            "role": "user",
            "content": user_input,
            "timestamp": datetime.now().isoformat()
        })
        
        # æ›´æ–°ä¸»è¯‰ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¾“å…¥ï¼‰
        if not state["chief_complaint"]:
            state["chief_complaint"] = user_input
        
        # æ·»åŠ åˆ°ç—‡çŠ¶åˆ—è¡¨
        if user_input not in state["symptoms"]:
            state["symptoms"].append(user_input)
        
        state["questions_asked"] += 1
        
        return state

    async def generate_question(
        self,
        state: DiagnosisState,
        on_chunk: Optional[Callable[[str], Awaitable[None]]] = None
    ) -> DiagnosisState:
        """ç”Ÿæˆä¸‹ä¸€ä¸ªé—®è¯Šé—®é¢˜ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰"""
        prompt = self.QUESTION_PROMPT.format(
            chief_complaint=state["chief_complaint"] or "æœªçŸ¥",
            symptoms=", ".join(state["symptoms"]) if state["symptoms"] else "æ— ",
            symptom_details=json.dumps(state["symptom_details"], ensure_ascii=False) if state["symptom_details"] else "æ— ",
            questions_asked=state["questions_asked"],
            messages=self._format_messages(state["messages"])
        )
        
        if on_chunk:
            question = await self._stream_llm(self.SYSTEM_PROMPT, prompt, on_chunk=on_chunk)
        else:
            question = await self._call_llm(self.SYSTEM_PROMPT, prompt)
        
        if not question:
            question = "èƒ½å¦è¯¦ç»†æè¿°ä¸€ä¸‹æ‚¨çš„ç—‡çŠ¶ï¼Ÿæ¯”å¦‚æŒç»­æ—¶é—´ã€ä¸¥é‡ç¨‹åº¦ç­‰ã€‚"
            if on_chunk:
                await on_chunk(question)
        
        state["current_question"] = question
        state["messages"].append({
            "role": "assistant",
            "content": question,
            "timestamp": datetime.now().isoformat()
        })
        
        return state

    async def generate_quick_options(self, state: DiagnosisState) -> DiagnosisState:
        """ç”Ÿæˆå¿«æ·é€‰é¡¹"""
        prompt = self.QUICK_OPTIONS_PROMPT.format(question=state["current_question"])
        
        response = await self._call_llm(self.SYSTEM_PROMPT, prompt, temperature=0.5)
        
        try:
            # å°è¯•è§£æJSON
            # å¤„ç†å¯èƒ½çš„markdownä»£ç å—
            if "```json" in response:
                response = response.split("```json")[1].split("```")[0]
            elif "```" in response:
                response = response.split("```")[1].split("```")[0]
            
            data = json.loads(response.strip())
            raw_options = data.get("options", [])
            
            # ç¡®ä¿æœ‰é»˜è®¤é€‰é¡¹
            has_negative = any("æ²¡æœ‰" in opt.get("text", "") or "ä¸" in opt.get("text", "") for opt in raw_options)
            if not has_negative:
                raw_options.append({"text": "éƒ½ä¸ç¬¦åˆ", "value": "éƒ½ä¸ç¬¦åˆ", "category": "å…¶ä»–"})
            
            formatted_options = []
            for opt in raw_options:
                text = opt.get("text") or opt.get("value") or ""
                if not text:
                    continue
                formatted_options.append({
                    "text": text,
                    "value": text,
                    "category": opt.get("category") or "å…¶ä»–"
                })
            
            state["quick_options"] = formatted_options[:5]  # æœ€å¤š5ä¸ªé€‰é¡¹
        except (json.JSONDecodeError, KeyError):
            # è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é€‰é¡¹
            state["quick_options"] = [
                {"text": "æ˜¯çš„", "value": "æ˜¯çš„", "category": "ç¡®è®¤"},
                {"text": "æ²¡æœ‰", "value": "æ²¡æœ‰", "category": "å¦å®š"},
                {"text": "ä¸ç¡®å®š", "value": "ä¸ç¡®å®š", "category": "ä¸ç¡®å®š"},
                {"text": "è¿˜æœ‰å…¶ä»–", "value": "è¿˜æœ‰å…¶ä»–", "category": "è¡¥å……"}
            ]
        
        return state

    async def assess_progress(self, state: DiagnosisState) -> DiagnosisState:
        """è¯„ä¼°é—®è¯Šè¿›åº¦ - ç”± AI é©±åŠ¨è¯„ä¼°"""
        prompt = self.ASSESSMENT_PROMPT.format(
            chief_complaint=state["chief_complaint"] or "æœªçŸ¥",
            symptoms=", ".join(state["symptoms"]) if state["symptoms"] else "æ— ",
            symptom_details=json.dumps(state["symptom_details"], ensure_ascii=False) if state["symptom_details"] else "æ— ",
            questions_asked=state["questions_asked"],
            messages=self._format_messages(state["messages"])
        )
        
        response = await self._call_llm(self.SYSTEM_PROMPT, prompt, temperature=0.3)
        
        try:
            if "```json" in response:
                response = response.split("```json")[1].split("```")[0]
            elif "```" in response:
                response = response.split("```")[1].split("```")[0]
            
            assessment = json.loads(response.strip())
            
            # è§£æ AI è¯„ä¼°çš„å®Œæ•´å­—æ®µ
            state["progress"] = assessment.get("progress", 0)
            state["should_diagnose"] = assessment.get("should_diagnose", False)
            state["can_conclude"] = assessment.get("can_conclude", False)
            state["confidence"] = assessment.get("confidence", 0)
            state["missing_info"] = assessment.get("missing_info", [])
            state["reasoning"] = assessment.get("reasoning", "")
            
        except (json.JSONDecodeError, KeyError):
            # Fallback: ä½¿ç”¨ç®€å•ç­–ç•¥è¯„ä¼°
            questions_asked = state["questions_asked"]
            symptoms_count = len(state["symptoms"])
            
            # ç®€å•è¿›åº¦è®¡ç®—
            state["progress"] = min(20 + questions_asked * 15, 90)
            # ç®€å•è¯Šæ–­è§¦å‘åˆ¤æ–­
            state["should_diagnose"] = questions_asked >= 5 and symptoms_count >= 2
            state["can_conclude"] = questions_asked >= 3 and symptoms_count >= 2
            state["confidence"] = min(30 + questions_asked * 10, 70)
            state["missing_info"] = []
            state["reasoning"] = "åŸºäºå·²æ”¶é›†ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼ˆfallbackç­–ç•¥ï¼‰"
        
        return state

    async def generate_diagnosis(
        self,
        state: DiagnosisState,
        on_chunk: Optional[Callable[[str], Awaitable[None]]] = None
    ) -> DiagnosisState:
        """ç”Ÿæˆè¯Šæ–­æŠ¥å‘Šï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰"""
        prompt = self.DIAGNOSIS_PROMPT.format(
            chief_complaint=state["chief_complaint"] or "æœªçŸ¥",
            symptom_details=json.dumps(state["symptom_details"], ensure_ascii=False) if state["symptom_details"] else json.dumps({"symptoms": state["symptoms"]}, ensure_ascii=False),
            messages=self._format_messages(state["messages"])
        )
        
        # è¯Šæ–­æŠ¥å‘Šéœ€è¦å®Œæ•´ JSONï¼Œä¸åšæµå¼è¾“å‡ºï¼Œä½†ç”Ÿæˆè¯Šæ–­æ¶ˆæ¯æ—¶å¯ä»¥æµå¼
        response = await self._call_llm(self.SYSTEM_PROMPT, prompt, temperature=0.5)
        
        try:
            if "```json" in response:
                response = response.split("```json")[1].split("```")[0]
            elif "```" in response:
                response = response.split("```")[1].split("```")[0]
            
            diagnosis = json.loads(response.strip())
            
            state["possible_diseases"] = diagnosis.get("diseases", [])
            state["risk_level"] = diagnosis.get("risk_level", "low")
            state["recommendations"] = {
                "summary": diagnosis.get("summary", ""),
                "risk_warning": diagnosis.get("risk_warning", ""),
                **diagnosis.get("recommendations", {})
            }
        except (json.JSONDecodeError, KeyError) as e:
            print(f"è¯Šæ–­æŠ¥å‘Šè§£æå¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤è¯Šæ–­
            state["possible_diseases"] = [
                {"name": "éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥", "probability": "å¾…å®š", "description": "å»ºè®®å‰å¾€åŒ»é™¢è¿›è¡Œè¯¦ç»†æ£€æŸ¥"}
            ]
            state["risk_level"] = "medium"
            state["recommendations"] = {
                "summary": f"æ ¹æ®æ‚¨æè¿°çš„ç—‡çŠ¶ï¼ˆ{', '.join(state['symptoms'][:3])}ï¼‰ï¼Œå»ºè®®å°½å¿«å°±åŒ»ã€‚",
                "department": "å…¨ç§‘/ç›¸å…³ä¸“ç§‘",
                "urgency": "å»ºè®®å°½å¿«å°±è¯Š",
                "lifestyle": ["æ³¨æ„ä¼‘æ¯", "ä¿æŒè‰¯å¥½ä½œæ¯", "å¦‚ç—‡çŠ¶åŠ é‡è¯·ç«‹å³å°±åŒ»"]
            }
        
        state["stage"] = "completed"
        state["progress"] = 100
        
        # ç”Ÿæˆè¯Šæ–­æ¶ˆæ¯
        diagnosis_msg = self._format_diagnosis_message(state)
        
        # å¦‚æœæœ‰æµå¼å›è°ƒï¼Œé€å­—ç¬¦è¾“å‡ºè¯Šæ–­æ¶ˆæ¯
        if on_chunk:
            for char in diagnosis_msg:
                await on_chunk(char)
        
        state["messages"].append({
            "role": "assistant",
            "content": diagnosis_msg,
            "timestamp": datetime.now().isoformat(),
            "is_diagnosis": True
        })
        state["current_question"] = diagnosis_msg
        
        return state

    def _format_diagnosis_message(self, state: DiagnosisState) -> str:
        """æ ¼å¼åŒ–è¯Šæ–­æ¶ˆæ¯"""
        recommendations = state.get("recommendations", {})
        diseases = state.get("possible_diseases", [])
        
        msg = f"ã€è¯Šæ–­æŠ¥å‘Šã€‘\n\n"
        msg += f"ğŸ“‹ ç—‡çŠ¶æ€»ç»“ï¼š\n{recommendations.get('summary', 'å·²æ”¶é›†æ‚¨çš„ç—‡çŠ¶ä¿¡æ¯')}\n\n"
        
        if diseases:
            msg += "ğŸ” å¯èƒ½çš„æƒ…å†µï¼š\n"
            for d in diseases[:3]:
                msg += f"â€¢ {d.get('name', 'æœªçŸ¥')}ï¼š{d.get('description', '')}\n"
            msg += "\n"
        
        risk_level = state.get("risk_level", "low")
        if risk_level in ["high", "emergency"]:
            msg += f"âš ï¸ é£é™©æç¤ºï¼š\n{recommendations.get('risk_warning', 'è¯·å°½å¿«å°±åŒ»')}\n\n"
        
        msg += f"ğŸ¥ å°±è¯Šå»ºè®®ï¼š\n"
        msg += f"â€¢ å»ºè®®ç§‘å®¤ï¼š{recommendations.get('department', 'ç›¸å…³ä¸“ç§‘')}\n"
        msg += f"â€¢ ç´§æ€¥ç¨‹åº¦ï¼š{recommendations.get('urgency', 'å»ºè®®å°±è¯Š')}\n\n"
        
        lifestyle = recommendations.get("lifestyle", [])
        if lifestyle:
            msg += "ğŸ’¡ ç”Ÿæ´»å»ºè®®ï¼š\n"
            for tip in lifestyle[:3]:
                msg += f"â€¢ {tip}\n"
        
        msg += "\nâš•ï¸ ä»¥ä¸Šå†…å®¹ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç”Ÿçš„è¯Šæ–­ï¼Œå¦‚æœ‰ä¸é€‚è¯·åŠæ—¶å°±åŒ»ã€‚"
        
        return msg

    def should_continue(self, state: DiagnosisState) -> str:
        """åˆ¤æ–­ä¸‹ä¸€æ­¥æµç¨‹ - åŸºäº AI è¯„ä¼°ç»“æœ"""
        # å¼ºåˆ¶å‡ºç»“è®ºï¼ˆç”¨æˆ·ç‚¹å‡»"ç›´æ¥å‡ºç»“è®º"æŒ‰é’®ï¼‰
        if state.get("force_conclude", False):
            return "diagnose"
        
        # AI åˆ¤æ–­åº”è¯¥è¿›å…¥è¯Šæ–­é˜¶æ®µ
        if state.get("should_diagnose", False):
            return "diagnose"
        
        # ç»§ç»­é—®è¯Š
        return "continue"

    async def run(
        self,
        state: DiagnosisState,
        user_input: str = None,
        force_conclude: bool = False,
        on_chunk: Optional[Callable[[str], Awaitable[None]]] = None
    ) -> DiagnosisState:
        """è¿è¡Œé—®è¯Šæµç¨‹ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰"""
        state["force_conclude"] = force_conclude
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯çœŸæ­£çš„æ–°ä¼šè¯ï¼ˆæ²¡æœ‰ä»»ä½•å¯¹è¯å†å²ï¼‰
        has_assistant_history = any(msg.get("role") == "assistant" for msg in state.get("messages", []))
        
        # åªåœ¨å®Œå…¨æ–°ä¼šè¯æ—¶æ‰é—®å€™
        if state["stage"] == "greeting" and not has_assistant_history:
            state = await self.greet(state)
            # é—®å€™è¯­ä¹Ÿå¯ä»¥æµå¼è¾“å‡º
            if on_chunk:
                for char in state["current_question"]:
                    await on_chunk(char)
            return state
        
        # å¦‚æœ stage è¿˜æ˜¯ greeting ä½†å·²æœ‰å¯¹è¯å†å²ï¼Œè¯´æ˜æ˜¯æ•°æ®åº“çŠ¶æ€æœªæ›´æ–°ï¼Œå¼ºåˆ¶åˆ‡æ¢åˆ° collecting
        if state["stage"] == "greeting":
            state["stage"] = "collecting"
        
        # åˆ†æç”¨æˆ·è¾“å…¥
        if user_input:
            state = await self.analyze_input(state, user_input)
        
        # è¯„ä¼°è¿›åº¦
        state = await self.assess_progress(state)
        
        # åˆ¤æ–­ä¸‹ä¸€æ­¥
        next_step = self.should_continue(state)
        
        if next_step == "diagnose":
            # ç”Ÿæˆè¯Šæ–­
            state = await self.generate_diagnosis(state, on_chunk=on_chunk)
        else:
            # ç»§ç»­é—®è¯Š
            state = await self.generate_question(state, on_chunk=on_chunk)
            state = await self.generate_quick_options(state)
        
        return state


def create_initial_state(consultation_id: str, user_id: int, chief_complaint: str = "") -> DiagnosisState:
    """åˆ›å»ºåˆå§‹é—®è¯ŠçŠ¶æ€"""
    return DiagnosisState(
        consultation_id=consultation_id,
        user_id=user_id,
        messages=[],
        chief_complaint=chief_complaint,
        symptoms=[],
        symptom_details={},
        stage="greeting",
        progress=0,
        questions_asked=0,
        current_question="",
        quick_options=[],
        reasoning="",
        possible_diseases=[],
        risk_level="low",
        recommendations={},
        can_conclude=False,
        force_conclude=False,
        # AIè¯„ä¼°å­—æ®µï¼ˆæ–°å¢ï¼‰
        should_diagnose=False,
        confidence=0,
        missing_info=[]
    )

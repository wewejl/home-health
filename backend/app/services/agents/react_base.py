"""
ReAct Agent åŸºç±»

å®ç° Observe â†’ Think â†’ Act å¾ªç¯çš„æ™ºèƒ½ä½“åŸºç±»
æ‰€æœ‰ç§‘å®¤æ™ºèƒ½ä½“ç»§æ‰¿æ­¤ç±»ï¼Œå®ç°å®Œå…¨è‡ªä¸»çš„ AI å†³ç­–
"""
import json
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, Callable, Awaitable, List
from typing_extensions import TypedDict, Annotated
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage

from ..qwen_service import QwenService
from ...schemas.agent_response import AgentResponse
from .tools import TOOL_REGISTRY, ALL_TOOL_SCHEMAS, execute_tools_parallel


class ReActAgentState(TypedDict, total=False):
    """ReAct Agent çŠ¶æ€"""
    # ä¼šè¯æ ‡è¯†
    session_id: str
    user_id: int
    agent_type: str
    
    # å¯¹è¯å†å²ï¼ˆLangGraph ç®¡ç†è¿½åŠ ï¼‰
    messages: Annotated[List[dict], add_messages]
    
    # AI å†³ç­–ï¼ˆç»“æ„åŒ– JSONï¼‰
    agent_decision: dict
    
    # å·¥å…·è°ƒç”¨
    pending_tool_calls: List[dict]
    tool_results: List[dict]
    
    # åŒ»å­¦ä¸Šä¸‹æ–‡ï¼ˆAI è‡ªå·±ç»´æŠ¤ï¼‰
    medical_context: dict
    
    # å“åº”è¾“å‡º
    current_response: str
    quick_options: List[str]
    
    # è¿›åº¦è¿½è¸ª
    stage: str  # greeting, collecting, analyzing, diagnosing, completed
    progress: int
    risk_level: str
    
    # é™„ä»¶
    attachments: List[dict]
    
    # ä¸“ç§‘æ•°æ®
    specialty_data: dict
    
    # æ§åˆ¶æ ‡è®°
    should_continue: bool
    iteration_count: int
    max_iterations: int
    
    # é”™è¯¯å¤„ç†
    error: Optional[str]


def create_react_initial_state(
    session_id: str, 
    user_id: int, 
    agent_type: str
) -> Dict[str, Any]:
    """åˆ›å»º ReAct Agent åˆå§‹çŠ¶æ€"""
    return {
        "session_id": session_id,
        "user_id": user_id,
        "agent_type": agent_type,
        "messages": [],
        "agent_decision": {},
        "pending_tool_calls": [],
        "tool_results": [],
        "medical_context": {
            "symptoms": [],
            "duration": "",
            "severity": "",
            "affected_area": "",
            "triggers": [],
            "medical_history": [],
            "allergies": [],
            "current_medications": [],
            "collected_info": [],
            "missing_info": []
        },
        "current_response": "",
        "quick_options": [],
        "stage": "greeting",
        "progress": 0,
        "risk_level": "low",
        "attachments": [],
        "specialty_data": {},
        "should_continue": True,
        "iteration_count": 0,
        "max_iterations": 10,
        "error": None,
    }


class ReActAgent(ABC):
    """
    ReAct Agent åŸºç±»

    å®ç° Observe â†’ Think â†’ Act å¾ªç¯
    AI è‡ªä¸»å†³ç­–ï¼Œæ— ç¡¬ç¼–ç è§„åˆ™

    æ–°å¢åŠŸèƒ½ï¼š
    - æ”¯æŒå¹¶è¡Œå·¥å…·æ‰§è¡Œ
    - æ”¯æŒ Corrective RAG
    """

    _compiled_graph = None

    def __init__(self, enable_parallel_tools: bool = True):
        self._tools = self.get_tools()
        self._tool_schemas = self.get_tool_schemas()
        self._enable_parallel_tools = enable_parallel_tools
    
    @property
    def graph(self):
        """è·å–ç¼–è¯‘åçš„å›¾ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self.__class__._compiled_graph is None:
            self.__class__._compiled_graph = self._build_graph()
        return self.__class__._compiled_graph
    
    @abstractmethod
    def get_system_prompt(self) -> str:
        """
        è·å–ç³»ç»Ÿæç¤ºè¯ - å­ç±»å¿…é¡»å®ç°
        
        å®šä¹‰æ™ºèƒ½ä½“çš„è§’è‰²ã€èƒ½åŠ›å’Œè¡Œä¸ºå‡†åˆ™
        """
        pass
    
    @abstractmethod
    def get_tools(self) -> List[str]:
        """
        è·å–æ™ºèƒ½ä½“å¯ç”¨çš„å·¥å…·åˆ—è¡¨ - å­ç±»å¿…é¡»å®ç°
        
        Returns:
            å·¥å…·åç§°åˆ—è¡¨ï¼Œå¦‚ ["search_medical_knowledge", "analyze_skin_image"]
        """
        pass
    
    def get_tool_schemas(self) -> List[dict]:
        """è·å–å·¥å…· Schemaï¼ˆç”¨äº Function Callingï¼‰"""
        from .tools import ALL_TOOL_SCHEMAS
        return [
            schema for schema in ALL_TOOL_SCHEMAS 
            if schema["function"]["name"] in self._tools
        ]
    
    @abstractmethod
    def get_capabilities(self) -> Dict[str, Any]:
        """è·å–æ™ºèƒ½ä½“èƒ½åŠ›é…ç½®"""
        pass
    
    def _build_graph(self) -> StateGraph:
        """æ„å»º ReAct çŠ¶æ€å›¾"""
        graph = StateGraph(ReActAgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        graph.add_node("reasoning", self._reasoning_node)
        graph.add_node("tool_executor", self._tool_executor_node)
        graph.add_node("response_generator", self._response_generator_node)
        
        # è®¾ç½®å…¥å£
        graph.set_entry_point("reasoning")
        
        # æ¡ä»¶è¾¹ï¼šæ ¹æ® AI å†³ç­–è·¯ç”±
        graph.add_conditional_edges(
            "reasoning",
            self._route_decision,
            {
                "use_tool": "tool_executor",
                "respond": "response_generator",
                "diagnose": "response_generator",
                "end": END,
            }
        )
        
        # å·¥å…·æ‰§è¡Œåå›åˆ°æ¨ç†
        graph.add_edge("tool_executor", "reasoning")
        
        # å“åº”ç”Ÿæˆåç»“æŸ
        graph.add_edge("response_generator", END)
        
        return graph.compile()
    
    def _route_decision(self, state: Dict[str, Any]) -> str:
        """æ ¹æ® AI å†³ç­–è·¯ç”±åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹"""
        decision = state.get("agent_decision", {})
        action = decision.get("action", "respond")
        
        # æ£€æŸ¥è¿­ä»£æ¬¡æ•°
        if state.get("iteration_count", 0) >= state.get("max_iterations", 10):
            return "respond"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if state.get("error"):
            return "respond"
        
        if action == "use_tool":
            return "use_tool"
        elif action == "diagnose":
            return "diagnose"
        elif action == "respond":
            return "respond"
        else:
            return "respond"
    
    async def _reasoning_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ¨ç†èŠ‚ç‚¹ - AI åˆ†æçŠ¶æ€å¹¶å†³å®šä¸‹ä¸€æ­¥
        
        è¿™æ˜¯ ReAct çš„æ ¸å¿ƒï¼šAI è‡ªä¸»å†³ç­–
        """
        state["iteration_count"] = state.get("iteration_count", 0) + 1
        
        # æ„å»ºæ¶ˆæ¯
        messages = self._build_reasoning_messages(state)
        
        # æ·»åŠ å†³ç­–æŒ‡ä»¤
        decision_instruction = self._get_decision_instruction(state)
        messages.append({"role": "user", "content": decision_instruction})
        
        try:
            # è°ƒç”¨ LLMï¼ˆå¸¦ Function Callingï¼‰
            result = await QwenService.chat_with_tools(
                messages=messages,
                tools=self._tool_schemas,
                tool_choice="auto",
                max_tokens=2000
            )
            
            # è§£æå†³ç­–
            if result.get("tool_calls"):
                # AI å†³å®šè°ƒç”¨å·¥å…·
                tool_calls = result["tool_calls"]
                state["pending_tool_calls"] = tool_calls
                state["agent_decision"] = {
                    "action": "use_tool",
                    "tool_calls": tool_calls,
                    "thought": result.get("content", "")
                }
            else:
                # AI å†³å®šç›´æ¥å›å¤
                content = result.get("content", "")
                decision = self._parse_decision(content)
                state["agent_decision"] = decision
                
                # æ›´æ–°åŒ»å­¦ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœ AI æä¾›äº†ï¼‰
                if decision.get("medical_context_update"):
                    self._update_medical_context(state, decision["medical_context_update"])
                
        except Exception as e:
            state["error"] = str(e)
            state["agent_decision"] = {
                "action": "respond",
                "response": "æŠ±æ­‰ï¼Œå¤„ç†æ—¶å‡ºç°äº†é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚"
            }
        
        return state
    
    def _build_reasoning_messages(self, state: Dict[str, Any]) -> List[dict]:
        """æ„å»ºæ¨ç†æ‰€éœ€çš„æ¶ˆæ¯åˆ—è¡¨"""
        messages = [
            {"role": "system", "content": self.get_system_prompt()}
        ]

        # æ·»åŠ å¯¹è¯å†å²
        for msg in state.get("messages", [])[-10:]:  # æœ€è¿‘10æ¡
            if isinstance(msg, dict):
                messages.append({
                    "role": msg.get("role", "user"),
                    "content": msg.get("content", "")
                })
            elif hasattr(msg, "type"):  # LangChain Message å¯¹è±¡
                role = "user" if msg.type == "human" else "assistant"
                messages.append({
                    "role": role,
                    "content": getattr(msg, "content", "")
                })

        # æ·»åŠ å·¥å…·è°ƒç”¨ç»“æœ
        for result in state.get("tool_results", []):
            messages.append({
                "role": "assistant",
                "content": f"[å·¥å…·è°ƒç”¨ç»“æœ] {result.get('tool')}: {json.dumps(result.get('result'), ensure_ascii=False)}"
            })

        # æ·»åŠ å½“å‰åŒ»å­¦ä¸Šä¸‹æ–‡
        ctx = state.get("medical_context", {})
        if ctx.get("symptoms") or ctx.get("collected_info"):
            context_summary = self._format_medical_context(ctx)
            messages.append({
                "role": "system",
                "content": f"[å½“å‰æ”¶é›†çš„ä¿¡æ¯]\n{context_summary}"
            })

        return messages
    
    def _get_decision_instruction(self, state: Dict[str, Any]) -> str:
        """è·å–å†³ç­–æŒ‡ä»¤"""
        attachments = state.get("attachments", [])
        has_image = any(
            att.get("type") == "image" or "image" in att.get("mime_type", "")
            for att in attachments
        )
        
        instruction = """è¯·åˆ†æå½“å‰å¯¹è¯çŠ¶æ€ï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚

ä½ å¯ä»¥ï¼š
1. è°ƒç”¨å·¥å…·è·å–æ›´å¤šä¿¡æ¯ï¼ˆsearch_medical_knowledge, assess_risk, analyze_skin_image, generate_medical_dossier, search_medicationï¼‰
2. ç»§ç»­è¿½é—®æ‚£è€…ä»¥æ”¶é›†æ›´å¤šä¿¡æ¯
3. ç»™å‡ºè¯Šæ–­å»ºè®®ï¼ˆå½“ä½ è®¤ä¸ºä¿¡æ¯å·²ç»å……åˆ†æ—¶ï¼‰

è¯·æ ¹æ®ä½ çš„ä¸“ä¸šåˆ¤æ–­å†³å®šä¸‹ä¸€æ­¥ã€‚å¦‚æœä½ è®¤ä¸ºå½“å‰ä¿¡æ¯è¶³å¤Ÿåšå‡ºåˆæ­¥è¯Šæ–­ï¼Œå¯ä»¥ç›´æ¥è¿›å…¥è¯Šæ–­é˜¶æ®µã€‚
å¦‚æœä½ éœ€è¦æ›´å¤šä¿¡æ¯ï¼Œè¯·ç»§ç»­è¿½é—®æˆ–è°ƒç”¨ç›¸å…³å·¥å…·ã€‚

ä½ çš„å†³ç­–åº”è¯¥åŸºäºï¼š
- å·²æ”¶é›†çš„ç—‡çŠ¶ä¿¡æ¯æ˜¯å¦å®Œæ•´
- æ˜¯å¦éœ€è¦æŸ¥è¯¢ä¸“ä¸šçŸ¥è¯†æ¥è¾…åŠ©åˆ¤æ–­
- æ˜¯å¦éœ€è¦è¯„ä¼°é£é™©ç­‰çº§
- æ˜¯å¦æœ‰å›¾ç‰‡éœ€è¦åˆ†æ"""

        if has_image:
            instruction += "\n\næ³¨æ„ï¼šæ‚£è€…ä¸Šä¼ äº†å›¾ç‰‡ï¼Œä½ å¯ä»¥è°ƒç”¨ analyze_skin_image å·¥å…·è¿›è¡Œåˆ†æã€‚"
        
        instruction += """

å¦‚æœä½ å†³å®šç›´æ¥å›å¤ï¼ˆä¸è°ƒç”¨å·¥å…·ï¼‰ï¼Œè¯·ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›å¤ï¼š
```json
{
  "thought": "ä½ çš„æ€è€ƒè¿‡ç¨‹",
  "action": "respond" æˆ– "diagnose",
  "response": "ç»™æ‚£è€…çš„å›å¤å†…å®¹",
  "quick_options": ["é€‰é¡¹1", "é€‰é¡¹2", "é€‰é¡¹3"],
  "medical_context_update": {
    "symptoms": ["æ–°å‘ç°çš„ç—‡çŠ¶"],
    "severity": "mild/moderate/severe",
    "missing_info": ["è¿˜éœ€è¦äº†è§£çš„ä¿¡æ¯"]
  },
  "ready_to_diagnose": true/false,
  "stage": "collecting" æˆ– "diagnosing",
  "progress": 0-100
}
```"""
        
        return instruction
    
    def _parse_decision(self, content: str) -> dict:
        """è§£æ AI çš„å†³ç­–è¾“å‡º"""
        # å°è¯•æå– JSON
        try:
            # æŸ¥æ‰¾ JSON å—
            import re
            json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
            
            # å°è¯•ç›´æ¥è§£æ
            if content.strip().startswith('{'):
                return json.loads(content)
            
        except json.JSONDecodeError:
            pass
        
        # è§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å†³ç­–
        return {
            "action": "respond",
            "response": content,
            "thought": "",
            "quick_options": []
        }
    
    def _update_medical_context(self, state: Dict[str, Any], update: dict):
        """æ›´æ–°åŒ»å­¦ä¸Šä¸‹æ–‡"""
        ctx = state.get("medical_context", {})
        
        for key, value in update.items():
            if key in ctx:
                if isinstance(ctx[key], list) and isinstance(value, list):
                    # åˆå¹¶åˆ—è¡¨ï¼Œå»é‡
                    ctx[key] = list(set(ctx[key] + value))
                else:
                    ctx[key] = value
        
        state["medical_context"] = ctx
    
    def _format_medical_context(self, ctx: dict) -> str:
        """æ ¼å¼åŒ–åŒ»å­¦ä¸Šä¸‹æ–‡ä¸ºæ–‡æœ¬"""
        parts = []
        
        if ctx.get("symptoms"):
            parts.append(f"ç—‡çŠ¶: {', '.join(ctx['symptoms'])}")
        if ctx.get("duration"):
            parts.append(f"ç—…ç¨‹: {ctx['duration']}")
        if ctx.get("severity"):
            parts.append(f"ä¸¥é‡ç¨‹åº¦: {ctx['severity']}")
        if ctx.get("affected_area"):
            parts.append(f"éƒ¨ä½: {ctx['affected_area']}")
        if ctx.get("triggers"):
            parts.append(f"è¯±å› : {', '.join(ctx['triggers'])}")
        if ctx.get("allergies"):
            parts.append(f"è¿‡æ•å²: {', '.join(ctx['allergies'])}")
        if ctx.get("missing_info"):
            parts.append(f"å¾…æ”¶é›†: {', '.join(ctx['missing_info'])}")
        
        return "\n".join(parts) if parts else "æš‚æ— "
    
    async def _tool_executor_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹

        æ”¯æŒå¹¶è¡Œæ‰§è¡Œå¤šä¸ªç‹¬ç«‹å·¥å…·ï¼Œæå‡å“åº”é€Ÿåº¦
        """
        pending_calls = state.get("pending_tool_calls", [])

        if not pending_calls:
            return state

        # é¢„å¤„ç†ï¼šæ³¨å…¥é™„ä»¶æ•°æ®åˆ°å›¾åƒåˆ†æå·¥å…·
        processed_calls = self._prepare_tool_calls(state, pending_calls)

        # æ‰§è¡Œå·¥å…·ï¼ˆå¹¶è¡Œæˆ–ä¸²è¡Œï¼‰
        if self._enable_parallel_tools and len(processed_calls) > 1:
            # å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥å…·
            execution_results = await execute_tools_parallel(
                processed_calls,
                TOOL_REGISTRY,
                enable_parallel=True
            )
        else:
            # ä¸²è¡Œæ‰§è¡Œï¼ˆå…¼å®¹æ¨¡å¼æˆ–å•ä¸ªå·¥å…·ï¼‰
            execution_results = await self._execute_tools_serial(processed_calls)

        # å¤„ç†ç»“æœå¹¶æ›´æ–°çŠ¶æ€
        results = state.get("tool_results", [])
        for result_item in execution_results:
            tool_name = result_item.get("tool")
            tool_result = result_item.get("result")
            success = result_item.get("success", False)

            results.append(result_item)

            # ç‰¹æ®Šå¤„ç†ï¼šæ›´æ–°çŠ¶æ€
            if success and tool_result:
                self._process_tool_result(state, tool_name, tool_result)

        state["tool_results"] = results
        state["pending_tool_calls"] = []
        state["attachments"] = []  # æ¸…ç©ºå·²å¤„ç†çš„é™„ä»¶

        return state

    def _prepare_tool_calls(
        self,
        state: Dict[str, Any],
        pending_calls: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        é¢„å¤„ç†å·¥å…·è°ƒç”¨ï¼Œæ³¨å…¥å¿…è¦çš„ä¸Šä¸‹æ–‡æ•°æ®

        ä¾‹å¦‚ï¼šå°†é™„ä»¶æ•°æ®æ³¨å…¥åˆ°å›¾åƒåˆ†æå·¥å…·
        """
        processed_calls = []
        attachments = state.get("attachments", [])
        medical_context = state.get("medical_context", {})

        for call in pending_calls:
            tool_name = call.get("function", {}).get("name", "")
            args_str = call.get("function", {}).get("arguments", "{}")

            try:
                args = json.loads(args_str)
            except json.JSONDecodeError:
                args = {}

            # ç‰¹æ®Šå¤„ç†å›¾åƒåˆ†æå·¥å…·ï¼šæ³¨å…¥é™„ä»¶æ•°æ®
            if tool_name == "analyze_skin_image" and not args.get("image_base64"):
                for att in attachments:
                    if att.get("type") == "image" or "image" in att.get("mime_type", ""):
                        args["image_base64"] = att.get("base64") or att.get("url", "")
                        args["context"] = medical_context.get("symptoms", [])
                        break

            # é‡æ–°æ„é€ å·¥å…·è°ƒç”¨
            processed_calls.append({
                "function": {
                    "name": tool_name,
                    "arguments": json.dumps(args, ensure_ascii=False)
                }
            })

        return processed_calls

    async def _execute_tools_serial(
        self,
        tool_calls: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        ä¸²è¡Œæ‰§è¡Œå·¥å…·ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
        """
        results = []

        for call in tool_calls:
            tool_name = call.get("function", {}).get("name", "")
            args_str = call.get("function", {}).get("arguments", "{}")

            try:
                args = json.loads(args_str)
            except json.JSONDecodeError:
                args = {}

            tool_func = TOOL_REGISTRY.get(tool_name)
            if tool_func:
                try:
                    result = await tool_func(**args)
                    results.append({
                        "tool": tool_name,
                        "args": args,
                        "result": result,
                        "success": True
                    })
                except Exception as e:
                    results.append({
                        "tool": tool_name,
                        "args": args,
                        "result": {"error": str(e)},
                        "success": False,
                        "error": str(e)
                    })
            else:
                results.append({
                    "tool": tool_name,
                    "args": args,
                    "result": {"error": f"å·¥å…· {tool_name} ä¸å­˜åœ¨"},
                    "success": False,
                    "error": f"Tool {tool_name} not found"
                })

        return results
    
    def _process_tool_result(self, state: Dict[str, Any], tool_name: str, result: dict):
        """å¤„ç†å·¥å…·ç»“æœï¼Œæ›´æ–°çŠ¶æ€"""
        specialty_data = state.get("specialty_data", {})
        
        if tool_name == "analyze_skin_image" and result.get("success"):
            specialty_data["skin_analysis"] = result
            state["progress"] = max(state.get("progress", 0), 50)
            
        elif tool_name == "assess_risk":
            state["risk_level"] = result.get("risk_level", "low")
            specialty_data["risk_assessment"] = result
            
        elif tool_name == "generate_medical_dossier":
            specialty_data["dossier"] = result
            state["stage"] = "completed"
            state["progress"] = 100
            
        elif tool_name == "search_medication":
            specialty_data["medication_info"] = result
        
        state["specialty_data"] = specialty_data
    
    async def _response_generator_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """å“åº”ç”ŸæˆèŠ‚ç‚¹"""
        decision = state.get("agent_decision", {})
        
        # è·å–å“åº”å†…å®¹
        response = decision.get("response", "")
        
        if not response:
            # å¦‚æœæ²¡æœ‰é¢„è®¾å“åº”ï¼Œæ ¹æ®è¡ŒåŠ¨ç±»å‹ç”Ÿæˆ
            action = decision.get("action", "respond")
            if action == "diagnose":
                response = await self._generate_diagnosis(state)
            else:
                response = "è¯·é—®è¿˜æœ‰ä»€ä¹ˆéœ€è¦äº†è§£çš„å—ï¼Ÿ"
        
        state["current_response"] = response
        state["quick_options"] = decision.get("quick_options", [])
        
        # æ›´æ–°é˜¶æ®µå’Œè¿›åº¦
        if decision.get("stage"):
            state["stage"] = decision["stage"]
        if decision.get("progress"):
            state["progress"] = decision["progress"]
        
        # å¦‚æœå‡†å¤‡è¯Šæ–­
        if decision.get("ready_to_diagnose") or decision.get("action") == "diagnose":
            state["stage"] = "diagnosing"
            state["progress"] = max(state.get("progress", 0), 80)
        
        return state
    
    async def _generate_diagnosis(self, state: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¯Šæ–­ï¼ˆç”± AI å®Œæˆï¼‰"""
        ctx = state.get("medical_context", {})
        specialty_data = state.get("specialty_data", {})

        diagnosis_prompt = f"""åŸºäºä»¥ä¸‹æ”¶é›†çš„ä¿¡æ¯ï¼Œè¯·ç»™å‡ºä¸“ä¸šçš„åˆæ­¥è¯Šæ–­æ„è§ï¼š

{self._format_medical_context(ctx)}

å›¾åƒåˆ†æç»“æœï¼š{specialty_data.get('skin_analysis', {}).get('findings', 'æ— ')}
é£é™©è¯„ä¼°ï¼š{specialty_data.get('risk_assessment', {}).get('risk_level', 'æœªè¯„ä¼°')}

è¯·åŒ…å«ï¼š
1. å¯èƒ½çš„è¯Šæ–­ï¼ˆæŒ‰å¯èƒ½æ€§æ’åºï¼‰
2. è¯Šæ–­ä¾æ®
3. å»ºè®®çš„å¤„ç†æ–¹å¼
4. æ˜¯å¦éœ€è¦çº¿ä¸‹å°±åŒ»
5. æ—¥å¸¸æŠ¤ç†å»ºè®®
6. æ³¨æ„äº‹é¡¹å’Œè­¦ç¤ºä¿¡å·

è¯·ç”¨ä¸“ä¸šä½†é€šä¿—æ˜“æ‡‚çš„è¯­è¨€å›å¤ã€‚"""

        messages = [
            {"role": "system", "content": self.get_system_prompt()},
            {"role": "user", "content": diagnosis_prompt}
        ]

        try:
            result = await QwenService.chat_with_tools(
                messages=messages,
                tools=[],
                max_tokens=1500
            )
            return result.get("content", "æ— æ³•ç”Ÿæˆè¯Šæ–­ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        except Exception as e:
            return f"ç”Ÿæˆè¯Šæ–­æ—¶å‡ºç°é—®é¢˜ï¼š{str(e)}"

    async def _handle_response_stream(
        self,
        state: Dict[str, Any],
        on_chunk: Optional[Callable[[str], Awaitable[None]]]
    ):
        """å¤„ç†å“åº”ç”ŸæˆèŠ‚ç‚¹çš„æµå¼è¾“å‡º"""
        decision = state.get("agent_decision", {})
        response = decision.get("response", "")

        if not response:
            action = decision.get("action", "respond")
            if action == "diagnose":
                # æµå¼ç”Ÿæˆè¯Šæ–­
                response = await self._generate_diagnosis_stream(state, on_chunk)
            else:
                response = "è¯·é—®è¿˜æœ‰ä»€ä¹ˆéœ€è¦äº†è§£çš„å—ï¼Ÿ"

        # æµå¼è¾“å‡ºå“åº”ï¼ˆé˜¶æ®µ 4: ä¼˜åŒ–ä¸ºåˆ†å—å‘é€ï¼Œæé«˜æ€§èƒ½ï¼‰
        if on_chunk and response:
            await self._stream_chunked(response, on_chunk, chunk_size=10)

        state["current_response"] = response
        state["quick_options"] = decision.get("quick_options", [])

        if decision.get("stage"):
            state["stage"] = decision["stage"]
        if decision.get("progress"):
            state["progress"] = decision["progress"]

    async def _stream_chunked(
        self,
        text: str,
        on_chunk: Callable[[str], Awaitable[None]],
        chunk_size: int = 10,
        delay: float = 0.005
    ):
        """
        é˜¶æ®µ 4 æ€§èƒ½ä¼˜åŒ–: åˆ†å—æµå¼å‘é€æ–‡æœ¬

        å°†æ–‡æœ¬åˆ†æˆå¤šä¸ªå—å‘é€ï¼Œè€Œä¸æ˜¯é€å­—ç¬¦å‘é€ï¼Œè¿™æ ·å¯ä»¥:
        - å‡å°‘ç½‘ç»œè¯·æ±‚æ¬¡æ•°
        - é™ä½ CPU å¼€é”€
        - ä¿æŒæµå¼è¾“å‡ºçš„è§†è§‰æ•ˆæœ

        Args:
            text: è¦å‘é€çš„æ–‡æœ¬
            on_chunk: å›è°ƒå‡½æ•°
            chunk_size: æ¯å—å­—ç¬¦æ•°ï¼ˆé»˜è®¤ 10ï¼‰
            delay: æ¯å—ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼Œé»˜è®¤ 0.005ï¼‰
        """
        import asyncio

        for i in range(0, len(text), chunk_size):
            chunk = text[i:i + chunk_size]
            await on_chunk(chunk)
            # åªåœ¨å—ä¹‹é—´æ·»åŠ å°å»¶è¿Ÿï¼Œä¿æŒæµå¼æ•ˆæœ
            if delay > 0:
                await asyncio.sleep(delay)

    async def _handle_reasoning_stream(
        self,
        state: Dict[str, Any],
        on_chunk: Optional[Callable[[str], Awaitable[None]]],
        show_thinking: bool
    ):
        """
        å¤„ç†æ¨ç†èŠ‚ç‚¹çš„æµå¼è¾“å‡º

        ä½¿ç”¨æµå¼ LLM è¿›è¡Œæ¨ç†ï¼Œå®æ—¶è¾“å‡º AI çš„æ€è€ƒè¿‡ç¨‹
        """
        # å‘é€æ€è€ƒçŠ¶æ€
        if show_thinking and on_chunk:
            await on_chunk({"type": "thinking", "data": "ğŸ¤” æ­£åœ¨åˆ†æ..."})

        # å¢åŠ è¿­ä»£è®¡æ•°
        state["iteration_count"] = state.get("iteration_count", 0) + 1

        # æ„å»ºæ¶ˆæ¯
        messages = self._build_reasoning_messages(state)

        # æ·»åŠ å†³ç­–æŒ‡ä»¤
        decision_instruction = self._get_decision_instruction(state)
        messages.append({"role": "user", "content": decision_instruction})

        try:
            # ä½¿ç”¨æµå¼ LLM è°ƒç”¨
            full_response = ""
            pending_tool_calls = []
            tool_calls_buffer = {}

            async for chunk in QwenService.chat_with_tools_stream(
                messages=messages,
                tools=self._tool_schemas,
                tool_choice="auto",
                max_tokens=2000
            ):
                chunk_type = chunk.get("type")

                if chunk_type == "content":
                    delta = chunk.get("delta", "")
                    full_response += delta
                    # å¦‚æœæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼Œå®æ—¶å‘é€ç»™å‰ç«¯
                    if show_thinking and on_chunk:
                        await on_chunk({"type": "thinking", "data": delta})

                elif chunk_type == "tool_call":
                    # AI å†³å®šè°ƒç”¨å·¥å…·
                    tool_call = chunk.get("tool_call", {})
                    pending_tool_calls.append(tool_call)

                    # å‘é€å·¥å…·è°ƒç”¨äº‹ä»¶
                    if on_chunk:
                        tool_name = tool_call.get("function", {}).get("name", "")
                        await on_chunk({
                            "type": "tool_call",
                            "data": {
                                "tool": tool_name,
                                "status": "calling"
                            }
                        })

                elif chunk_type == "done":
                    break

            # å¤„ç†å†³ç­–ç»“æœ
            if pending_tool_calls:
                # AI å†³å®šè°ƒç”¨å·¥å…·
                state["pending_tool_calls"] = pending_tool_calls
                state["agent_decision"] = {
                    "action": "use_tool",
                    "tool_calls": pending_tool_calls,
                    "thought": full_response
                }
            else:
                # AI å†³å®šç›´æ¥å›å¤
                decision = self._parse_decision(full_response)
                state["agent_decision"] = decision

                # æ›´æ–°åŒ»å­¦ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœ AI æä¾›äº†ï¼‰
                if decision.get("medical_context_update"):
                    self._update_medical_context(state, decision["medical_context_update"])

        except Exception as e:
            state["error"] = str(e)
            state["agent_decision"] = {
                "action": "respond",
                "response": "æŠ±æ­‰ï¼Œå¤„ç†æ—¶å‡ºç°äº†é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚"
            }

            # å‘é€é”™è¯¯äº‹ä»¶
            if on_chunk:
                await on_chunk({
                    "type": "thinking",
                    "data": f"âŒ å‡ºç°é”™è¯¯: {str(e)}"
                })

    async def _generate_diagnosis_stream(
        self,
        state: Dict[str, Any],
        on_chunk: Optional[Callable[[str], Awaitable[None]]]
    ) -> str:
        """æµå¼ç”Ÿæˆè¯Šæ–­"""
        ctx = state.get("medical_context", {})
        specialty_data = state.get("specialty_data", {})

        diagnosis_prompt = f"""åŸºäºä»¥ä¸‹æ”¶é›†çš„ä¿¡æ¯ï¼Œè¯·ç»™å‡ºä¸“ä¸šçš„åˆæ­¥è¯Šæ–­æ„è§ï¼š

{self._format_medical_context(ctx)}

å›¾åƒåˆ†æç»“æœï¼š{specialty_data.get('skin_analysis', {}).get('findings', 'æ— ')}
é£é™©è¯„ä¼°ï¼š{specialty_data.get('risk_assessment', {}).get('risk_level', 'æœªè¯„ä¼°')}

è¯·åŒ…å«ï¼š
1. å¯èƒ½çš„è¯Šæ–­ï¼ˆæŒ‰å¯èƒ½æ€§æ’åºï¼‰
2. è¯Šæ–­ä¾æ®
3. å»ºè®®çš„å¤„ç†æ–¹å¼
4. æ˜¯å¦éœ€è¦çº¿ä¸‹å°±åŒ»
5. æ—¥å¸¸æŠ¤ç†å»ºè®®
6. æ³¨æ„äº‹é¡¹å’Œè­¦ç¤ºä¿¡å·

è¯·ç”¨ä¸“ä¸šä½†é€šä¿—æ˜“æ‡‚çš„è¯­è¨€å›å¤ã€‚"""

        messages = [
            {"role": "system", "content": self.get_system_prompt()},
            {"role": "user", "content": diagnosis_prompt}
        ]

        full_response = ""
        async for chunk in QwenService.chat_with_tools_stream(
            messages=messages,
            tools=[],
            max_tokens=2000
        ):
            chunk_type = chunk.get("type")

            if chunk_type == "content":
                delta = chunk.get("delta", "")
                full_response += delta
                if on_chunk:
                    await on_chunk(delta)
            elif chunk_type == "done":
                break
            elif chunk_type == "error":
                full_response = "ç”Ÿæˆè¯Šæ–­æ—¶å‡ºç°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚"
                break

        return full_response or "æ— æ³•ç”Ÿæˆè¯Šæ–­ï¼Œè¯·ç¨åé‡è¯•ã€‚"
    
    async def run_stream(
        self,
        state: Dict[str, Any],
        user_input: str = None,
        attachments: list = None,
        action: str = "conversation",
        on_chunk: Optional[Callable[[str], Awaitable[None]]] = None,
        show_thinking: bool = False,
        **kwargs
    ) -> AgentResponse:
        """
        æµå¼è¿è¡Œ ReAct Agent

        Args:
            state: å½“å‰ä¼šè¯çŠ¶æ€
            user_input: ç”¨æˆ·è¾“å…¥
            attachments: é™„ä»¶åˆ—è¡¨
            action: åŠ¨ä½œç±»å‹
            on_chunk: æµå¼è¾“å‡ºå›è°ƒ
            show_thinking: æ˜¯å¦æ˜¾ç¤º AI æ€è€ƒè¿‡ç¨‹

        Returns:
            AgentResponse
        """
        # é‡ç½®è¿­ä»£è®¡æ•°
        state["iteration_count"] = 0
        state["tool_results"] = []
        state["pending_tool_calls"] = []

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        if user_input:
            if "messages" not in state:
                state["messages"] = []
            state["messages"].append({"role": "user", "content": user_input})

        # å¤„ç†é™„ä»¶
        if attachments:
            state["attachments"] = attachments

        try:
            # ä½¿ç”¨ astream è€Œä¸æ˜¯ ainvoke
            async for event in self.graph.astream(state):
                # LangGraph astream è¿”å›çš„æ˜¯ (node_name, node_state) å…ƒç»„
                # æˆ–è€…ç›´æ¥è¿”å›çŠ¶æ€æ›´æ–°
                if isinstance(event, tuple):
                    node_name, node_state = event
                else:
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ __metadata__ æˆ–å…¶ä»–æ ‡è¯†
                    if isinstance(event, dict):
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ LangGraph çš„æµå¼äº‹ä»¶æ ¼å¼
                        metadata = event.get("__metadata__", {})
                        node_name = metadata.get("name", "") if metadata else ""
                        node_state = event
                    else:
                        node_name = ""
                        node_state = event

                # å¤„ç†ä¸åŒèŠ‚ç‚¹çš„æµå¼è¾“å‡º
                if node_name == "reasoning":
                    await self._handle_reasoning_stream(
                        node_state, on_chunk, show_thinking
                    )
                elif node_name == "tool_executor":
                    # å‘é€å·¥å…·æ‰§è¡ŒçŠ¶æ€
                    if on_chunk:
                        pending_calls = node_state.get("pending_tool_calls", [])
                        for call in pending_calls:
                            tool_name = call.get("function", {}).get("name", "")
                            # å‘é€å·¥å…·æ‰§è¡ŒçŠ¶æ€
                            await on_chunk({
                                "type": "tool_call",
                                "data": {
                                    "tool": tool_name,
                                    "status": "executing"
                                }
                            })
                        # å‘é€å·¥å…·æ‰§è¡Œå®ŒæˆçŠ¶æ€
                        results = node_state.get("tool_results", [])
                        if results:
                            for result in results:
                                if result.get("success"):
                                    await on_chunk({
                                        "type": "tool_result",
                                        "data": {
                                            "tool": result.get("tool"),
                                            "status": "success"
                                        }
                                    })
                elif node_name == "response_generator":
                    await self._handle_response_stream(
                        node_state, on_chunk
                    )

            # è·å–æœ€ç»ˆçŠ¶æ€ï¼ˆnode_state æ˜¯æœ€åçš„çŠ¶æ€ï¼‰
            final_state = node_state if 'node_state' in locals() else state

            # åºåˆ—åŒ–çŠ¶æ€ä»¥ä¾¿ä¿å­˜åˆ°æ•°æ®åº“
            serialized_state = self._serialize_state_for_db(final_state)

            # æ„å»ºå“åº”
            return AgentResponse(
                message=final_state.get("current_response", ""),
                stage=final_state.get("stage", "collecting"),
                progress=final_state.get("progress", 0),
                quick_options=final_state.get("quick_options", []),
                risk_level=final_state.get("risk_level"),
                specialty_data=final_state.get("specialty_data"),
                next_state=serialized_state
            )

        except Exception as e:
            import traceback
            traceback.print_exc()
            return AgentResponse(
                message=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é—®é¢˜: {str(e)}",
                stage=state.get("stage", "collecting"),
                progress=state.get("progress", 0),
                quick_options=[],
                next_state=state
            )

    async def run(
        self,
        state: Dict[str, Any],
        user_input: str = None,
        attachments: list = None,
        action: str = "conversation",
        on_chunk: Optional[Callable[[str], Awaitable[None]]] = None,
        **kwargs  # å…¼å®¹é¢å¤–å‚æ•°
    ) -> AgentResponse:
        """
        è¿è¡Œ ReAct Agent
        
        Args:
            state: å½“å‰ä¼šè¯çŠ¶æ€
            user_input: ç”¨æˆ·è¾“å…¥
            attachments: é™„ä»¶åˆ—è¡¨
            action: åŠ¨ä½œç±»å‹
            on_chunk: æµå¼è¾“å‡ºå›è°ƒ
            
        Returns:
            AgentResponse
        """
        # é‡ç½®è¿­ä»£è®¡æ•°
        state["iteration_count"] = 0
        state["tool_results"] = []
        state["pending_tool_calls"] = []
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        if user_input:
            if "messages" not in state:
                state["messages"] = []
            state["messages"].append({"role": "user", "content": user_input})
        
        # å¤„ç†é™„ä»¶
        if attachments:
            state["attachments"] = attachments
        
        try:
            # è¿è¡ŒçŠ¶æ€å›¾
            final_state = await self.graph.ainvoke(state)

            # åºåˆ—åŒ–çŠ¶æ€ä»¥ä¾¿ä¿å­˜åˆ°æ•°æ®åº“
            serialized_state = self._serialize_state_for_db(final_state)

            # æ„å»ºå“åº”
            return AgentResponse(
                message=final_state.get("current_response", ""),
                stage=final_state.get("stage", "collecting"),
                progress=final_state.get("progress", 0),
                quick_options=final_state.get("quick_options", []),
                risk_level=final_state.get("risk_level"),
                specialty_data=final_state.get("specialty_data"),
                next_state=serialized_state
            )
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return AgentResponse(
                message=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é—®é¢˜: {str(e)}",
                stage=state.get("stage", "collecting"),
                progress=state.get("progress", 0),
                quick_options=[],
                next_state=state
            )
    
    @classmethod
    def reset_graph(cls):
        """é‡ç½®ç¼–è¯‘åçš„å›¾"""
        cls._compiled_graph = None

    def _serialize_state_for_db(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†çŠ¶æ€åºåˆ—åŒ–ä¸º JSON å¯åºåˆ—åŒ–çš„æ ¼å¼

        LangGraph çš„ add_messages ä¼šåœ¨çŠ¶æ€ä¸­æ·»åŠ  LangChain Message å¯¹è±¡ï¼Œ
        è¿™äº›å¯¹è±¡æ— æ³•ç›´æ¥åºåˆ—åŒ–åˆ° JSONï¼Œéœ€è¦è½¬æ¢ä¸ºæ™®é€šå­—å…¸
        """
        serialized = {}
        for key, value in state.items():
            # è·³è¿‡ç‰¹å®šå­—æ®µ
            if key.startswith("_"):
                continue

            # å¤„ç† LangChain Message å¯¹è±¡åˆ—è¡¨
            if isinstance(value, list) and value:
                if all(isinstance(item, BaseMessage) for item in value):
                    # å…¨æ˜¯ Message å¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—å…¸
                    serialized[key] = [
                        {"type": msg.type, "content": msg.content}
                        for msg in value
                    ]
                    continue
                elif all(isinstance(item, (dict, str, int, float, bool, type(None))) for item in value):
                    # åŸºæœ¬ç±»å‹åˆ—è¡¨ï¼Œç›´æ¥ä¿ç•™
                    serialized[key] = value
                    continue
                else:
                    # æ··åˆç±»å‹ï¼Œé€ä¸ªå¤„ç†
                    serialized[key] = []
                    for item in value:
                        if isinstance(item, BaseMessage):
                            serialized[key].append({"type": item.type, "content": item.content})
                        elif isinstance(item, dict):
                            serialized[key].append(self._serialize_dict(item))
                        else:
                            serialized[key].append(item)
                    continue

            # å¤„ç†å­—å…¸
            if isinstance(value, dict):
                serialized[key] = self._serialize_dict(value)
            else:
                # åŸºæœ¬ç±»å‹ç›´æ¥ä¿ç•™
                serialized[key] = value

        return serialized

    def _serialize_dict(self, d: Dict[str, Any]) -> Dict[str, Any]:
        """é€’å½’åºåˆ—åŒ–å­—å…¸ä¸­çš„é JSON ç±»å‹"""
        result = {}
        for k, v in d.items():
            if isinstance(v, BaseMessage):
                result[k] = {"type": v.type, "content": v.content}
            elif isinstance(v, dict):
                result[k] = self._serialize_dict(v)
            elif isinstance(v, list):
                result[k] = [
                    {"type": item.type, "content": item.content} if isinstance(item, BaseMessage) else item
                    for item in v
                ]
            else:
                result[k] = v
        return result


# å…¼å®¹æ—§ç‰ˆå¯¼å…¥ - åˆ«å
create_initial_state = create_react_initial_state
LangGraphAgent = ReActAgent
AgentState = ReActAgentState

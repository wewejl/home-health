"""
çš®è‚¤ç§‘ LangGraph Agent

åŸºäº LangGraph 1.x å®ç°çš„é«˜æ€§èƒ½çš®è‚¤ç§‘æ™ºèƒ½ä½“
- å›¾ç»“æ„å¤ç”¨ï¼Œé¿å…é‡å¤ç¼–è¯‘
- ç²¾ç®€ Promptï¼Œé™ä½ Token æ¶ˆè€—
- æµå¼è¾“å‡ºæ”¯æŒ
"""
from typing import Dict, Any, List
from langgraph.graph import StateGraph, END, START
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage

from ..base.langgraph_base import LangGraphAgentBase
from ..llm_provider import LLMProvider
from .derma_state import DermaState, create_derma_initial_state
from .output_models import ConversationOutput, DiagnosisOutput
from .prompts import (
    DERMA_CONVERSATION_PROMPT,
    DERMA_IMAGE_ANALYSIS_PROMPT,
    DERMA_DIAGNOSIS_PROMPT,
    DERMA_GREETING_TEMPLATE,
    DERMA_QUICK_OPTIONS_GREETING,
    DERMA_QUICK_OPTIONS_COLLECTING,
    DERMA_QUICK_OPTIONS_DIAGNOSIS,
)


def _get_message_content(msg) -> str:
    """å®‰å…¨æå–æ¶ˆæ¯å†…å®¹ï¼Œå…¼å®¹ dict å’Œ LangChain Message å¯¹è±¡"""
    if isinstance(msg, dict):
        return msg.get("content", "")
    elif hasattr(msg, "content"):
        return msg.content
    return str(msg)


def _get_message_role(msg) -> str:
    """å®‰å…¨æå–æ¶ˆæ¯è§’è‰²ï¼Œå…¼å®¹ dict å’Œ LangChain Message å¯¹è±¡"""
    if isinstance(msg, dict):
        return msg.get("role", "")
    elif hasattr(msg, "type"):
        # LangChain message types: human, ai, system
        return "assistant" if msg.type == "ai" else msg.type
    return ""


class DermaLangGraphAgent(LangGraphAgentBase):
    """
    çš®è‚¤ç§‘ LangGraph Agent
    
    çŠ¶æ€å›¾ç»“æ„ï¼š
        START -> router -> greeting/conversation/image_analysis/diagnosis -> END
    
    æ€§èƒ½ä¼˜åŒ–ï¼š
        - é—®å€™èŠ‚ç‚¹æ— éœ€ LLM è°ƒç”¨
        - å›¾ç»“æ„ç±»çº§åˆ«ç¼“å­˜
        - LLM å®ä¾‹å¤ç”¨
    """
    
    def _create_initial_state(self, session_id: str, user_id: int) -> DermaState:
        """åˆ›å»ºçš®è‚¤ç§‘åˆå§‹çŠ¶æ€"""
        return create_derma_initial_state(session_id, user_id)
    
    def _build_graph(self) -> StateGraph:
        """æ„å»ºçš®è‚¤ç§‘çŠ¶æ€å›¾"""
        graph = StateGraph(DermaState)
        
        # æ·»åŠ èŠ‚ç‚¹
        graph.add_node("router", self._route_node)
        graph.add_node("greeting", self._greeting_node)
        graph.add_node("conversation", self._conversation_node)
        graph.add_node("image_analysis", self._image_analysis_node)
        graph.add_node("diagnosis", self._diagnosis_node)
        
        # è®¾ç½®å…¥å£ç‚¹
        graph.add_edge(START, "router")
        
        # è·¯ç”±æ¡ä»¶è¾¹
        graph.add_conditional_edges(
            "router",
            self._get_next_node,
            {
                "greeting": "greeting",
                "conversation": "conversation",
                "image_analysis": "image_analysis",
                "diagnosis": "diagnosis",
                "end": END
            }
        )
        
        # èŠ‚ç‚¹åç»­æµè½¬ - éƒ½å›åˆ° END
        graph.add_edge("greeting", END)
        graph.add_edge("conversation", END)
        graph.add_edge("image_analysis", END)
        graph.add_edge("diagnosis", END)
        
        return graph.compile()
    
    # === è·¯ç”±é€»è¾‘ ===
    
    def _route_node(self, state: DermaState) -> DermaState:
        """è·¯ç”±å†³ç­–èŠ‚ç‚¹"""
        # æ–°ä¼šè¯ -> é—®å€™
        if state["stage"] == "greeting" and state["questions_asked"] == 0:
            has_history = any(_get_message_role(m) == "assistant" for m in state["messages"])
            if not has_history:
                state["next_node"] = "greeting"
                return state
        
        # æœ‰å¾…å¤„ç†å›¾ç‰‡ -> å›¾ç‰‡åˆ†æ
        if state["pending_attachments"]:
            state["next_node"] = "image_analysis"
            return state
        
        # åˆ¤æ–­æ˜¯å¦åº”è¯¥è¯Šæ–­
        if self._should_diagnose(state):
            state["next_node"] = "diagnosis"
            return state
        
        # é»˜è®¤ç»§ç»­å¯¹è¯
        state["next_node"] = "conversation"
        return state
    
    def _get_next_node(self, state: DermaState) -> str:
        """è¿”å›ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°"""
        return state.get("next_node", "conversation")
    
    def _should_diagnose(self, state: DermaState) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»™å‡ºè¯Šæ–­"""
        if not state["messages"]:
            return False
            
        last_msg = _get_message_content(state["messages"][-1]) if state["messages"] else ""
        
        # ç”¨æˆ·æ˜ç¡®è¯·æ±‚è¯Šæ–­
        diagnosis_keywords = ["æ€ä¹ˆåŠ", "æ˜¯ä»€ä¹ˆ", "ä»€ä¹ˆç—…", "å»ºè®®", "ä¸¥é‡å—", "éœ€è¦æ²»ç–—", "ç”¨ä»€ä¹ˆè¯"]
        user_wants_diagnosis = any(kw in last_msg for kw in diagnosis_keywords)
        
        # ä¿¡æ¯è¶³å¤Ÿ
        has_enough_info = (
            bool(state.get("chief_complaint")) and
            bool(state.get("skin_location")) and
            len(state.get("symptoms", [])) >= 1
        )
        
        # å¯¹è¯è¶³å¤Ÿé•¿
        enough_rounds = state["questions_asked"] >= 3
        
        return user_wants_diagnosis or (has_enough_info and enough_rounds)
    
    # === èŠ‚ç‚¹å®ç° ===
    
    async def _greeting_node(self, state: DermaState) -> DermaState:
        """é—®å€™èŠ‚ç‚¹ - æ— éœ€ LLM è°ƒç”¨ï¼Œå¿«é€Ÿå“åº”"""
        state["current_response"] = DERMA_GREETING_TEMPLATE
        state["stage"] = "collecting"
        state["quick_options"] = DERMA_QUICK_OPTIONS_GREETING
        state["next_node"] = "end"
        return state
    
    async def _conversation_node(self, state: DermaState) -> DermaState:
        """å¯¹è¯èŠ‚ç‚¹ - é—®è¯Šæ”¶é›†ä¿¡æ¯"""
        llm = LLMProvider.get_llm()
        
        # è·å–æœ€æ–°ç”¨æˆ·è¾“å…¥
        user_input = ""
        if state["messages"]:
            user_input = _get_message_content(state["messages"][-1])
        
        # æ„å»º Prompt
        prompt = ChatPromptTemplate.from_messages([
            ("system", DERMA_CONVERSATION_PROMPT),
            ("human", """é—®è¯Šä¿¡æ¯ï¼š
- ä¸»è¯‰: {chief_complaint}
- éƒ¨ä½: {skin_location}
- ç—‡çŠ¶: {symptoms}
- å·²é—®è¯Š {questions_asked} è½®

ç”¨æˆ·è¯´ï¼š{user_input}

è¯·ç»§ç»­é—®è¯Šæˆ–ç»™å‡ºå»ºè®®ã€‚è¾“å‡º JSON æ ¼å¼ï¼š
{{"message": "ä½ çš„å›å¤", "next_action": "continueæˆ–complete", "extracted_info": {{"chief_complaint": "", "skin_location": "", "duration": "", "symptoms": []}}, "quick_options": [{{"text": "é€‰é¡¹æ–‡æœ¬", "value": "é€‰é¡¹å€¼", "category": "ç±»åˆ«"}}]}}""")
        ])
        
        try:
            # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º
            chain = prompt | llm.with_structured_output(ConversationOutput)
            
            result = await chain.ainvoke({
                "chief_complaint": state.get("chief_complaint") or "æœªæ˜ç¡®",
                "skin_location": state.get("skin_location") or "æœªæ˜ç¡®",
                "symptoms": ", ".join(state.get("symptoms", [])) or "æœªæ˜ç¡®",
                "questions_asked": state["questions_asked"],
                "user_input": user_input
            })
            
            # æ›´æ–°çŠ¶æ€
            state["current_response"] = result.message
            state["quick_options"] = result.quick_options or DERMA_QUICK_OPTIONS_COLLECTING
            state["questions_asked"] += 1
            
            # æ›´æ–°åŒ»å­¦ä¿¡æ¯
            if result.extracted_info:
                self._update_medical_info(state, result.extracted_info)
            
            # ä¸‹ä¸€æ­¥
            if result.next_action == "complete":
                state["next_node"] = "diagnosis"
                state["stage"] = "diagnosis"
            else:
                state["next_node"] = "end"
                
        except Exception as e:
            # é™çº§å¤„ç†ï¼šç›´æ¥ä½¿ç”¨ LLM
            state["current_response"] = "è¯·ç»§ç»­æè¿°æ‚¨çš„ç—‡çŠ¶ï¼Œæˆ‘ä¼šå¸®æ‚¨åˆ†æã€‚"
            state["quick_options"] = DERMA_QUICK_OPTIONS_COLLECTING
            state["questions_asked"] += 1
            state["next_node"] = "end"
        
        return state
    
    async def _image_analysis_node(self, state: DermaState) -> DermaState:
        """å›¾ç‰‡åˆ†æèŠ‚ç‚¹ - å¤šæ¨¡æ€ LLM"""
        llm = LLMProvider.get_multimodal_llm()
        
        # è·å–å¾…å¤„ç†å›¾ç‰‡
        if not state["pending_attachments"]:
            state["current_response"] = "æ²¡æœ‰æ£€æµ‹åˆ°å›¾ç‰‡ï¼Œè¯·ä¸Šä¼ çš®è‚¤é—®é¢˜çš„ç…§ç‰‡ã€‚"
            state["next_node"] = "end"
            return state
        
        attachment = state["pending_attachments"].pop(0)
        image_base64 = attachment.get("base64", "")
        
        # ç¡®ä¿ base64 æ ¼å¼æ­£ç¡®
        if image_base64 and not image_base64.startswith("data:"):
            image_base64 = f"data:image/jpeg;base64,{image_base64}"
        
        try:
            # æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯
            messages = [
                SystemMessage(content=DERMA_IMAGE_ANALYSIS_PROMPT),
                HumanMessage(content=[
                    {"type": "image_url", "image_url": {"url": image_base64}},
                    {"type": "text", "text": f"è¯·åˆ†æè¿™å¼ çš®è‚¤å›¾ç‰‡ã€‚æ‚£è€…ä¸»è¯‰ï¼š{state.get('chief_complaint') or 'æœªè¯´æ˜'}"}
                ])
            ]
            
            response = await llm.ainvoke(messages)
            
            # è§£æç»“æœ
            analysis = {
                "message": response.content,
                "type": "image_analysis",
                "attachment_id": attachment.get("id", "")
            }
            
            # æ›´æ–°çŠ¶æ€
            state["skin_analyses"].append(analysis)
            state["latest_analysis"] = analysis
            state["current_response"] = response.content
            state["processed_results"].append({
                "type": "image_analysis",
                "result": analysis
            })
            state["stage"] = "analyzing"
            
        except Exception as e:
            state["current_response"] = f"å›¾ç‰‡åˆ†ææ—¶å‡ºç°é—®é¢˜ï¼Œè¯·å°è¯•é‡æ–°ä¸Šä¼ æ¸…æ™°çš„ç…§ç‰‡ã€‚"
            state["error"] = str(e)
        
        state["next_node"] = "end"
        return state
    
    async def _diagnosis_node(self, state: DermaState) -> DermaState:
        """è¯Šæ–­èŠ‚ç‚¹ - ç»¼åˆåˆ†æç»™å‡ºå»ºè®®"""
        llm = LLMProvider.get_llm()
        
        # è·å–å›¾ç‰‡åˆ†æç»“æœ
        image_analysis_text = ""
        if state.get("skin_analyses"):
            image_analysis_text = state["skin_analyses"][-1].get("message", "")
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", DERMA_DIAGNOSIS_PROMPT),
            ("human", """è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç»™å‡ºè¯Šæ–­å»ºè®®ï¼š

- ä¸»è¯‰: {chief_complaint}
- éƒ¨ä½: {skin_location}
- æŒç»­æ—¶é—´: {duration}
- ç—‡çŠ¶: {symptoms}
- å›¾ç‰‡åˆ†æ: {image_analysis}

è¾“å‡º JSON æ ¼å¼ï¼š
{{"diagnosis_message": "è¯Šæ–­è¯´æ˜", "conditions": [{{"name": "ç–¾ç—…å", "probability": "likely/possible/unlikely", "basis": "ä¾æ®"}}], "risk_level": "low/medium/high/emergency", "care_advice": "æŠ¤ç†å»ºè®®", "treatment_suggestions": ["å»ºè®®1"], "need_offline_visit": false, "follow_up_days": 7}}""")
        ])
        
        try:
            chain = prompt | llm.with_structured_output(DiagnosisOutput)
            
            result = await chain.ainvoke({
                "chief_complaint": state.get("chief_complaint", "") or "æœªæ˜ç¡®",
                "skin_location": state.get("skin_location", "") or "æœªæ˜ç¡®",
                "duration": state.get("duration", "") or "æœªæ˜ç¡®",
                "symptoms": ", ".join(state.get("symptoms", [])) or "æœªæ˜ç¡®",
                "image_analysis": image_analysis_text or "æ— å›¾ç‰‡åˆ†æ"
            })
            
            # æ ¼å¼åŒ–è¯Šæ–­ä¿¡æ¯ä¸ºç”¨æˆ·å‹å¥½çš„æ–‡æœ¬
            formatted_response = self._format_diagnosis_response(result)
            
            # æ›´æ–°çŠ¶æ€
            state["current_response"] = formatted_response
            state["possible_conditions"] = [c.model_dump() for c in result.conditions]
            state["risk_level"] = result.risk_level
            state["care_advice"] = result.care_advice
            state["need_offline_visit"] = result.need_offline_visit
            state["stage"] = "completed"
            state["quick_options"] = DERMA_QUICK_OPTIONS_DIAGNOSIS
            
        except Exception as e:
            state["current_response"] = "æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œå»ºè®®æ‚¨åˆ°çš®è‚¤ç§‘å°±è¯Šè·å¾—æ›´å‡†ç¡®çš„è¯Šæ–­ã€‚"
            state["stage"] = "completed"
            state["error"] = str(e)
        
        state["next_node"] = "end"
        return state
    
    # === è¾…åŠ©æ–¹æ³• ===
    
    def _format_diagnosis_response(self, result: DiagnosisOutput) -> str:
        """
        å°†ç»“æ„åŒ–è¯Šæ–­ç»“æœæ ¼å¼åŒ–ä¸ºç”¨æˆ·å‹å¥½çš„æ–‡æœ¬
        
        é¿å…ç›´æ¥æ˜¾ç¤º JSON æ ¼å¼ï¼Œæä¾›æ¸…æ™°çš„è¯Šæ–­è¯´æ˜
        """
        lines = []
        
        # è¯Šæ–­è¯´æ˜
        if result.diagnosis_message:
            lines.append(result.diagnosis_message)
            lines.append("")
        
        # å¯èƒ½çš„è¯Šæ–­
        if result.conditions:
            lines.append("**å¯èƒ½çš„è¯Šæ–­ï¼š**")
            for condition in result.conditions:
                probability_text = {
                    "likely": "è¾ƒå¯èƒ½",
                    "possible": "å¯èƒ½",
                    "unlikely": "ä¸å¤ªå¯èƒ½"
                }.get(condition.probability, condition.probability)
                
                lines.append(f"\nâ€¢ **{condition.name}**ï¼ˆ{probability_text}ï¼‰")
                lines.append(f"  ä¾æ®ï¼š{condition.basis}")
            lines.append("")
        
        # æŠ¤ç†å»ºè®®
        if result.care_advice:
            lines.append("**æŠ¤ç†å»ºè®®ï¼š**")
            lines.append(result.care_advice)
            lines.append("")
        
        # æ²»ç–—å»ºè®®
        if result.treatment_suggestions:
            lines.append("**æ²»ç–—å»ºè®®ï¼š**")
            for suggestion in result.treatment_suggestions:
                lines.append(f"â€¢ {suggestion}")
            lines.append("")
        
        # å°±åŒ»æé†’
        if result.need_offline_visit:
            risk_emoji = {
                "emergency": "ğŸš¨",
                "high": "âš ï¸",
                "medium": "â„¹ï¸",
                "low": "ğŸ’¡"
            }.get(result.risk_level, "â„¹ï¸")
            
            lines.append(f"{risk_emoji} **é‡è¦æé†’ï¼š**")
            lines.append("å»ºè®®æ‚¨å°½å¿«åˆ°çš®è‚¤ç§‘å°±è¯Šï¼Œè·å¾—ä¸“ä¸šåŒ»ç”Ÿçš„é¢è¯Šå’Œç¡®è¯Šã€‚")
            
            if result.follow_up_days:
                lines.append(f"å»ºè®® {result.follow_up_days} å¤©å†…å¤è¯Šã€‚")
        
        return "\n".join(lines)
    
    def _update_medical_info(self, state: DermaState, extracted_info: Dict[str, Any]):
        """æ›´æ–°åŒ»å­¦ä¿¡æ¯"""
        if extracted_info.get("chief_complaint"):
            state["chief_complaint"] = extracted_info["chief_complaint"]
        
        if extracted_info.get("skin_location"):
            state["skin_location"] = extracted_info["skin_location"]
        
        if extracted_info.get("duration"):
            state["duration"] = extracted_info["duration"]
        
        if extracted_info.get("symptoms"):
            for symptom in extracted_info["symptoms"]:
                if symptom and symptom not in state["symptoms"]:
                    state["symptoms"].append(symptom)
    
    def get_capabilities(self) -> Dict[str, Any]:
        """è·å–èƒ½åŠ›é…ç½®"""
        return {
            "actions": ["conversation", "analyze_skin", "interpret_report"],
            "accepts_media": ["image/jpeg", "image/png", "application/pdf"],
            "ui_components": ["TextBubble", "SkinAnalysisCard", "ReportInterpretationCard"],
            "description": "çš®è‚¤ç§‘AIæ™ºèƒ½ä½“ï¼ˆLangGraphï¼‰ï¼Œæ”¯æŒçš®è‚¤å½±åƒåˆ†æå’ŒæŠ¥å‘Šè§£è¯»"
        }
